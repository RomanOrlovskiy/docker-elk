input {
	beats {
		port => 5000
	}
}

## Add your filters / logstash plugins configuration here
filter {
	json {
      source => "message"
    }
    mutate {
      rename => { "log" => "message" }
    }
    date {
      match => [ "time", "ISO8601" ]
    }

	# Matches apache access logs and parses as JSON
    grok {
        match => { "message" => "%{COMMONAPACHELOG}" }
    }

	# Matches default Tomcat catalina logs and parses into JSON
	# Probably will not work properly for multiline stack trace logs
	grok {
	
	  # This directory should be available from the container, so it has to shared via a volume
      patterns_dir => ["/usr/share/logstash/pipeline/patterns"]
      match => {
		# MY_DATE_PATTERN - custom pattern for Tomcat date format configured in a text file in the above directory
        "message" => "%{MY_DATE_PATTERN:timestamp}%{SPACE}%{GREEDYDATA:loglevel}%{SPACE}\[%{GREEDYDATA:thread}\]%{SPACE}%{JAVACLASS:classname}%{SPACE}%{GREEDYDATA:logmessage}"
      }
    }
    date {
      match => [ "timestamp" , "dd-MMM-yyyy HH:mm:ss.SSS" ]
    }
}

output {
    stdout { codec => rubydebug }
	elasticsearch {
			hosts => "elasticsearch:9200"
			user => "elastic"
			password => "changeme"
			index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
	}
}
